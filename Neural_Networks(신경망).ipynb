{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks(신경망).ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPI0OwnLl7HHYfK4VqQxMJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Deeplearning/blob/master/Neural_Networks(%EC%8B%A0%EA%B2%BD%EB%A7%9D).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdT0Rd3suZXl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#지도학습 알고리즘 : Neural Networks(신경망) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7iDWVx4uZaD",
        "colab_type": "text"
      },
      "source": [
        "<b>What is this?</b>\n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/proxy/v5Xg1L5jbb075BVkOg7-04NZ81PbLOa1hbUu93wPt7IIH8C0vaPprh7aNVzJOXDXn4vcB-7dLFpCX1dY8dfUeE6RQpAqfRHnZ5MzMaiDD9MtiJ18KFOaxI8CJngZTU3kmvWG0akP893TJx1woHjcH-syf7YP0iZzW4wX0A\">\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "인간의 두뇌는 약 800억 개의 뉴런으로 이뤄진 네트워크이며, 그 덕분에 우리가 예전에 봤던 것과는 다른 형태로 표현된 객체도 인식할 수 있다. 이러한 뉴런들의 상호작용으로 입력 신호(기린의 사진)를 레이블(기린)로 변환하며, **신경망(neural networks)**은 이러한 원리를 바탕으로 착안됐다.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**신경망이 최근 큰 인기를 끄는 핵심적인 이유?**\n",
        "- 데이터 저장과 공유 방식의 진보\n",
        "- 컴퓨팅 파워 증가. 중앙 처리 장치(CPU)보다 150배 빠른 **그래픽 처리 장치(GPU)**는 원래 게임 분야에서 고품질 컴퓨터 이미지를 표현하기 위해 사용됐지만, 대규모 데이터 세트를 이용해 신경망을 학습할 때 중요한 엔진 역할을 할 수 있다는 것이 밝혀짐\n",
        "- 개선된 알고리즘. 기계가 인간 두뇌의 성능을 따라잡는 일은 지금까지 난제로 남아 있었지만, 그 성능을 크게 향상시킬 수 있는 여러 가지 기법이 개발됨 \n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "> **[참고] 신경망 용어**<br>\n",
        "\n",
        "인공신경망 최초의 개념인 '퍼셉트론' 1957년 등장했었다. 초기의 뉴럴 네트워크 모델이며, 2중 퍼셉트론부터 '신경망(Neural Networks)'이라는 이름을 사용하기 시작하였다. 다층 퍼셉트론부터는 '인공신경망(Artificial) NN' 이라고 부르기 시작했다.은닉층이 2개 이상인 신경망은 심층 신경망(Deep NN)이라고 한다. 학습을 시키는 인공 신경망이 심층 신경망일 경우에 이를 심층 신경망을 학습시킨다고 하여, '딥 러닝'이라고 한다.\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "> **[참고] 단층 퍼셉트론의 한계**<br>\n",
        "\n",
        "하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능하다. 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능했다. 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말한다.\n",
        "<br>\n",
        "<br>\n",
        "<img src=\"https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG\">\n",
        "<br>\n",
        "XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능하다. 다층 퍼셉르톤(은닉층)을 통해 가능해진다.\n",
        "<br>\n",
        "<img src=\"https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG\">\n",
        "<br>\n",
        "<img src=\"https://wikidocs.net/images/page/24958/perceptron3_final.PNG\"> → <img src=\"https://wikidocs.net/images/page/24958/perceptron_4image.jpg\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3_m1lJuZgG",
        "colab_type": "text"
      },
      "source": [
        "## 1. 신경망을 학습하는 방법\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Kofi_Appiah/publication/252028600/figure/fig2/AS:298067136925718@1448076151592/Some-samples-of-the-MNIST-database.png\">\n",
        "\n",
        "\n",
        "기계가 이미지를 읽으려면 우선 픽셀로 변환해야 한다. 검은 픽셀은 '0'으로, 흰색 픽셀은 '1'로 표현한다. 이미지가 컬러 이미지라면 적색과 녹색, 청색(RGB)의 색조값을 이용할 수 있다.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<img src=\"https://static.javatpoint.com/tutorial/tensorflow/images/mnist-dataset-in-cnn3.png\">\n",
        "<br>\n",
        "<br>\n",
        "이미지를 양자화한 후 신경망에 전달한다. 네트워크에 수기 숫자 이미지와 각 이미지가 나타내는 실제 숫자의 레이블을 함께 제공한다. 이렇게 이미지와 그에 상응하는 레이블을 학습시킨 후, 레이블이 없는 새로운 이미지를 인식하는지 테스트 한다. 물론 '3','5'를 혼동하기도 하고, '2'와 '7','8'을 오인식하는 오류를 범하기도 하나, 그럼에도 불구하고 **신경망은 전체적인 정확도를 유지함과 동시에 사람보다 훨씬 빠르게 동작한다**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTPG72BquZjs",
        "colab_type": "text"
      },
      "source": [
        "## 2. 인공신경망의 구성 요소\n",
        "수기 숫자를 인식하기 위해 신경망은 뉴런으로 이뤄진 여러 레이어를 거쳐 이미지를 처리하고 예측 결과를 계산한다. 일반적인 신경망 구성은 다음과 같다.\n",
        "\n",
        "- 입력 계층 : 입력된 이미지의 모든 픽셀을 처리하는 레이어. **이미지에 포함된 뉴런의 개수와 같은 수의 뉴런을 포함**한다. 더 나은 예측을 위해 컨볼루션 레이어를 사용할 수 있다. 각 픽셀을 따로 처리하는 대신, 컨볼류션 레이어는 픽셀의 조합을 바탕으로 특징을 찾는다. 예를 들어, 숫자 '6'에는 원이나 위쪽을 향하는 꼬리 모양이 존재한다. 이러한 분석 방식의 특징은 위치가 아니라 존재 여부에만 의존적이므로 핵심적인 특징이 가운데에서 빗겨나 존재해도 신경망이 숫자를 인식할 수 있다. 이러한 성질을 일컬어 위치 불변성(translational invariance)라고 한다.\n",
        "\n",
        "- 은닉 레이어(hidden layer) : 픽셀이 신경망에 입력된 후, 여러 레이어를 거쳐 네트워크가 각 레이블에 대해 예전에 학습했던 이미지와의 유사성을 계산하는 변환을 수행한다.좀 더 높은 정확도를 위해 더 많은 변환을 사용할 수 있지만, 처리 시간이 길어진다. 하지만 일반적으로 적은 수의 레이어만으로도 충분하다. 각 레이어의 뉴런 개수는 이미지에 포함된 픽셀 개수에 비례해야 한다. \n",
        "\n",
        "- 출력 레이어 : 최종 예측을 표현하는 레이어로써 가능한 출력의 개수에 따라 하나 또는 그 이상의 뉴런으로 구성된다. \n",
        "\n",
        "- 손실 레이어(loss layer) : 신경망을 학습시키는 동안에는 손실 레이어가 필요하다. 일반적으로 끝에 위치하며, 입력이 제대로 인식됐는지의 여부에 따라 오차의 정도에 대한 피드백을 출력한다.\n",
        "  - 오차제곱합 함수 (가장 많이 쓰임)\n",
        "  - 교차 엔트로피 오차 함수 \n",
        "\n",
        "**손실 레이어**는 신경망 학습에서 핵심적인 역할을 한다. 올바른 예측을 한 경우에는 손실 계층의 피드백으로 인해 예측에 영향을 미친 활성화 경로상의 뉴런을 강화한다. 잘못된 예측을 한 경우, 활성화 경로상의 뉴런으로 오차가 전달돼 오차를 줄이는 방향으로 활성화 기준을 재조정한다. 이런 과정을 **역전파(backpropagation)** 라고 한다.\n",
        "<br>\n",
        "<br>\n",
        ">**[참고] 인공 신경망 학습 방법**\n",
        "- 1) 입력에 대해서 순전파(forward propagation) 연산 \n",
        "- 2) 그리고 순전파 연산을 통해 나온 예측값과 실제값의 오차를 손실 함수(loss function)을 통해 계산\n",
        "- 3) 그리고 이 손실(loss)을 미분을 통해서 기울기(gradient) 계산\n",
        "- 4) 이를 통해 역전파(back propagation)를 수행\n",
        "<br>\n",
        "<img src=\"https://i.stack.imgur.com/H1KsG.png\">\n",
        "\n",
        "\n",
        "**이러한 반복적인 학습 과정에서 신경망은 입력 신호와 올바른 출력 레이블 사이의 연관 관계를 학습하며, 학습된 연관 관계는 각 뉴런에 활성화 규칙(activation rule)이라는 형태로 프로그래밍된다. *따라서 신경망의 정확도를 높이려면 활성화 규칙에 영향을 미치는 구성 요소를 튜닝해야 한*다.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKT8BK4uZu2",
        "colab_type": "text"
      },
      "source": [
        "## 3. 활성화 함수\n",
        "<br><img src=\"https://wikidocs.net/images/page/24987/activation_function_final.PNG\"><br>\n",
        "활성화 함수(활성화 규칙)이란, 뉴런이 활성화되는 데 필요한 입력 신호의 출처와 강도를 규정한다. 신경망 학습 과정에서 이 규칙이 미세하게 튜닝된다. 학습이 진행되면서 레이어간 연관돼 있다는 것을 학습한다. 연관 관계는 강도가 각기 다른데, 그 강도를 가중값이라 하고 w로 표기한다. 이 연관 관계에는 방향성이 있다. 예를 들어 가중값이 -1 이라면 전달되는 입력 신호는 감소한다.\n",
        "\n",
        "즉, 활성화 activation란 말 그대로 입력신호의 총합이 활성화를 일으킬지 정하는 역할을 한다. 그 정하는 것을 하는 내용들이 함수 안에 담겨 있는 것이다. ( = **출력값을 반환하기 위해 무언가를 처리해주는 변환기**)\n",
        "\n",
        "> #### 1) 계단함수 (step function)<br>\n",
        "\n",
        "퍼셉트론(단층 퍼셉트론)은 활성화 함수로 step function(계단 함수)를 이용한다. 특정 임계값을 넘기면 활성화되는 함수이다. 아래 왼쪽(a)가 계단 함수이다. 0에서 멈추어있다. 어느 기점에서 1로 바뀐다. (Input의 값이 weight와 계산하여 다 더하고 사전에 설정한 임계값(threshold)과 비교해서 임계값을 넘으면 Output으로 1을 출력하고, 0을 출력했다.)\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Raja_Ali5/publication/306038981/figure/fig14/AS:393836095393798@1470909250163/Figure-3-Two-basic-activation-functions-a-Step-Function-b-Sigmoid-Function.ppm\">\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "> #### 2) 시그모이드 함수 (sigmoid function)<br>\n",
        "\n",
        "신경망에서 주로 이용하는 활성화 함수는 시그모이드 함수이다. 아래는 시그모이드 함수를 나타낸 식이다. e는 자연상수로 2.7192...의 값을 갖는 실수 이다. 계단함수에 비해 완만한 곡선 형태로 비선형이다. 특정 경계를 기준으로 출력이 확 바뀌어버리는 계단함수와는 달리 시그모이드 함수는 완만하게 매끄럽게 변화하는데 이 매끄러움이 신경망 학습에서 중요하며 활성화 함수로 시그모이드 함수를 사용하는 이유이기도 하다.\n",
        "시그모이드 함수는 값을 실수형으로 가지는 것을 볼 수 있다. 시그모이드 함수의 매끄러움은 가중치 값을 전달할 때 좀 더 부드럽게 양을 조절해서 전달할 수 있다는 점이 계단 함수와 다른 점이다. \n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\">\n",
        "\n",
        "**퍼셉트론과 신경망의 주된 차이는 이 활성화 함수뿐이다. 그 외에 뉴런이 여러 층으로 이어지는 구조와 신호를 전달하는 방법은 기본적으로 동일하다.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 계단/시그모이드 공통점 \n",
        "- 입력이 작을 때는 출력은 0에 가깝고 입력이 커지면 출력이 1에 가까워진다.\n",
        "- 입력이 아무리 작거나 커도 출력은 0에서 1 사이이다.\n",
        "- 비선형 함수이다. (선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없기 때문에 반드시 비선형 함수여야 함)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4FwgTAf_UTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### 계단함수 구현 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def step_function(x):\n",
        "    return np.array(x>0, dtype=np.int) # 배열의 타입을 int로 변환해준다.\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1) # np.arange() = -5.0에서 5.0 전까지 0.1 간격의 넘파이 배열을 생성함\n",
        "y = step_function(x)\n",
        "plt.plot(x,y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJmWWJxB_U-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### 시그모이드 함수 구현\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def sigmoid(x):\n",
        "    return 1 / (1+ np.exp(-x))    # 인수 x가 넘파이 배열이어도 올바른 결과가 나오게함.\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "x\n",
        "\n",
        "y = sigmoid(x)\n",
        "plt.plot(x,y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUMieUTsuZ1J",
        "colab_type": "text"
      },
      "source": [
        "## 4. 다차원 배열 계산\n",
        "\n",
        "다차원 배열의 계산은 앞서 설명한 가중치의 값을 보다 편하게 하기 위해서 행렬 연산을 이용하는 것이다. 한 두개의 신경망 층은 인간이 계산할 수 있을지 모르겠지만 그 이상의 수 많은 차원의 수많은 뉴런층으로 구성된 신경망의 weight를 일일이 계산하는 것은 불가능한 일이다. 이를 컴퓨팅적으로도 쉽게 할 수 있도록 돕는 것이 행렬 연산이다.(선형대수 개념 학습 필요!)\n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/992F0D3359E6FFD404\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdNYj7OCHT9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력층에서 1층으로의 신호 전달\n",
        "X= np.array([1.0, 0.5])\n",
        "W1= np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "B1= np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "print(W1.shape)\n",
        "print(X.shape)\n",
        "print(B1.shape)\n",
        "\n",
        "A1 = np.dot(X, W1) + B1\n",
        "Z1 = sigmoid(A1)\n",
        "print(A1)\n",
        "print(Z1)    # 1층의 출력 값\n",
        "\n",
        "# 1층에서 2층으로의 신호 전달\n",
        "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "B2 = np.array([0.1, 0.2])\n",
        "\n",
        "print(Z1.shape)   # 2층의 입력 값\n",
        "print(W2.shape)\n",
        "print(B1.shape)\n",
        "\n",
        "A2 = np.dot(Z1, W2) + B2\n",
        "Z2 = sigmoid(A2)   # 2층의 출력 값, 3층의 입력 값\n",
        "print(A2)\n",
        "print(Z2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDr30TlyuZ8Q",
        "colab_type": "text"
      },
      "source": [
        "## 5. 출력층 설계\n",
        "신경망은 분류(classification)와 회귀(regression) 문제에 모두 활용할 수 있다. 어떤 문제냐에 따라 활성화 함수가 달라질 뿐이다. 분류는 어떤 사람이 사기를 쳤는지(1), 안 쳤는지(0) 예측하는 것이고, 회귀는 사기당한 금액이 얼마($10,000)였는지 에측하는 문제이다. 둘다 크게 보면 예측(prediction)이다.\n",
        "\n",
        "- 회귀 --> 항등 함수 (출력 값을 그대로 반환하는 함수) identity function\n",
        "- 분류(0/1) --> 시그모이드 함수 sigmoid function\n",
        "- 분류(multiple) --> 소프트맥스 함수 softmax function\n",
        "\n",
        "출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 한다. 예를 들어 입력 이미지를 숫자 0부터 9 중 하나로 분류하는 문제라면 출력층 뉴런을 10개로 설정한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piwwIutzday7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2층 신경망 구현하기 \n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "    \n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        \n",
        "        return y\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):         # predict()의 결과와 정답 레이블을 바탕으로 교차 엔트로피 오차를 구함 \n",
        "        y = self.predict(x)\n",
        "        \n",
        "        return cross_entropy_error(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "\n",
        "    def numerical_gradient(self, x, t):    # 수치 미분방식으로 각 매개변수의 손실함수에 대한 기울기 계산\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):    # 오차역전파법을 사용한 기울기 계산\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        grads = {}\n",
        "        \n",
        "        batch_num = x.shape[0]\n",
        "        \n",
        "        # forward\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        \n",
        "        # backward\n",
        "        dy = (y - t) / batch_num\n",
        "        grads['W2'] = np.dot(z1.T, dy)\n",
        "        grads['b2'] = np.sum(dy, axis=0)\n",
        "        \n",
        "        da1 = np.dot(dy, W2.T)\n",
        "        dz1 = sigmoid_grad(a1) * da1\n",
        "        grads['W1'] = np.dot(x.T, dz1)\n",
        "        grads['b1'] = np.sum(dz1, axis=0)\n",
        "\n",
        "        return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU1UekVruaC7",
        "colab_type": "text"
      },
      "source": [
        "# [1] Convolutional Neural Network (CNN) / 합성곱 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOeHW0VcuaIN",
        "colab_type": "text"
      },
      "source": [
        "- CNN은 **필터링 기법**을 인공신경망에 적용함으로써 이미지를 더욱 효과적으로 처리하기 위해 (LeCun et al., 1989)에서 처음 소개되었으며, 이후에 (LeCun et al., 1998)에서 현재 딥 러닝에서 이용되고 있는 형태의 CNN이 제안되었다.\n",
        "\n",
        "- 합성곱 신경망(Convolutional neural network, CNN)은 시각적 이미지를 분석하는 데 사용되는 깊고 피드-포워드적인 인공신경망의 한 종류이다. 딥 러닝에서 심층 신경망으로 분류되며, **시각적 이미지 분석에 가장 일반적**으로 적용된다. 또한 공유 가중치 구조와 변환 불변성 특성에 기초하여 변이 불변 또는 공간 불변 인공 신경망 (SIANN)으로도 알려져 있다. 이미지 및 비디오 인식, 추천 시스템, 이미지 분류, 의료 이미지 분석 및 자연어 처리에 응용된다.\n",
        "\n",
        "- 뉴런 사이의 연결 패턴이 동물 시각 피질의 조직과 유사하다는 생물학적 과정에 의해 영감을 받았다. 개별 피질 뉴런은 수용장으로 알려진 시야의 **제한된 영역에서만 자극에 반응**한다. 상이한 뉴런의 수용 필드는 전체 시야를 커버하도록 부분적으로 중첩된다.\n",
        "\n",
        "- 다층 퍼셉트론은 일반적으로 완전히 연결된 네트워크, 즉 한 계층의 각 뉴런이 다음 계층의 모든 뉴런에 연결됨을 의미한다. 이러한 네트워크의 \"완전히 연결\"은 주어진 데이터에 과적합 되는 경향이 있다. 일반적인 정규화 방법에는 손실 함수에 몇 가지 형태의 가중치 측정을 추가하는 것이 포함되지만, CNN은 정규화를 향한 다른 접근 방식을 취한다. **데이터에서 계층적 패턴을 활용하고 더 작고 간단한 패턴을 사용하여 더 복잡한 패턴을 조립**한다. 따라서 연결성과 복잡성의 규모에서 CNN은 극단적으로 낮다. \n",
        "\n",
        "- CNN은 다른 이미지 분류 알고리즘에 비해 상대적으로 전처리를 거의 사용하지 않는다. 이는 네트워크가 기존 알고리즘에서 수작업으로 제작된 필터를 학습한다는 것을 의미한다. **피처 디자인에 대한 사전 지식과 인간 노력과의 독립성은 CNN의 주요한 장점다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ne80qGuZzs",
        "colab_type": "text"
      },
      "source": [
        "## FNN 문제점\n",
        "\n",
        "출처: https://excelsior-cjh.tistory.com/79 [EXCELSIOR]\n",
        ">**문제점1. 벡터화로 인한 인접 픽셀 간 상관관계 무시하는 오류**<br>\n",
        "\n",
        "이미지를 처리할 때 발생하는 FNN의 첫 번째 문제점은 인접 픽셀 간의 상관관계가 무시된다는 것이다. FNN은 벡터형태로 표현된 데이터를 입력 받는다.그러나 이미지 데이터에서는 일반적으로 인접 픽셀간의 매누 높은 상관관계가 존재하기 때문에 이미지를 벡터화하는 과정에서 막대한 정보 손실이 발생한다. \n",
        "\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile2.uf.tistory.com%2Fimage%2F998AC44C5C66A23C05385E\">\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        ">**문제점2. 막대한 양의 파라미터(변수의 개수, 네트워크 크기, 학습시간)**<br>\n",
        "\n",
        "만약 FNN을 사용하여 1024*1024 크기의 컬러 이미지를 처리하고자 한다면, FNN에 입력되는 벡터의 차원은 약 315만[(=1024 X 1024 X 3)]이라는 막대한 수가 된다. 300만 차원의 입력을 처리하기 위해서는 필연적으로 막대한 양의 뉴런이 필요하고 이에 따라 인공신경망 전체의 모델 파라미터는 기하급수적으로 증가한다.\n",
        "<br><br>\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/25406B3358F470F135?download\">\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0XAfLxTuZ6g",
        "colab_type": "text"
      },
      "source": [
        "## 1. CNN의 구조\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "> 인공신경망 구조\n",
        "\n",
        "일반적인 인공신경망은 그림 2와 같이 affine으로 명시된 fully-connected 연산과 ReLU와 같은 비선형 활성 함수 (nonlinear activation function)의 합성으로 정의된 계층을 여러 층 쌓은 구조이다.\n",
        "층이 4개인 완전연결 신경망은 다음과 같이 구현할 수 있다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F99B2694E5C5D97EA0DEE54\">\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "\n",
        "> CNN 구조\n",
        "\n",
        "CNN은 그림 3과 같이 **합성곱 계층 (convolutional layer)과 풀링 계층 (pooling layer)**이라고 하는 새로운 층을 fully-connected 계층 이전에 추가함으로써 원본 이미지에 필터링 기법을 적용한 뒤에 필터링된 이미에 대해 분류 연산이 수행되도록 구성된다.\n",
        "\n",
        "- 일반적 신경망의 'Affine-ReLU' 연결이 **'Conv-ReLU-(Pooling)'**으로 바뀐 것이다. (Pooling 층은 생략할 수 있다)\n",
        "- 출력에서 가까운 층에서는 Fully-connected layer 사용 가능하다.\n",
        "\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F99C9CD495C5D99AC01C905\">\n",
        "\n",
        "즉, 합성곱 계층은 이미지에 **필터링 기법**이 적용하고, **풀링 계층은 이미지의 국소적인 부분들을 하나의 대표적인 스칼라 값으로 변환**함으로써 이미지의 크기를 줄이는 등의 다양한 기능들을 수행한다.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "> CNN 구조의 장점\n",
        "\n",
        "  - **CNN은 이미지의 형태를 보존하도록 행렬 형태의 데이터를 입력** 받기 때문에 이미지를 벡터화하는 과정에서 발생하는 정보 손실을 방지할 수 있다. 이러한 이유로 이미지를 다루는 문제에 대해서는 대부분 CNN 이 이용되고 잇다.\n",
        "\n",
        "  - CNN을 이용한다면 단순히 필터들을 모수화(parameterizaion)할 수 있을 정도의 파라미터만 필요하며,\n",
        "  - CNN의 마지막 fully-connected layer는 원본 이미지가 아닌 풀링 계층을 통해 축소된 이미지를 처리하기 때문에 fully-connected layer의 가중치 또한 크게 줄어든다.\n",
        "  - CNN은 기존 FNN보다 매우 적은 model parameter를 갖는다는 점 때문에 이미지 뿐만 아니라 다양한 고차원 데이터에 대해서도 광범위 하게 활용되고 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXkE3N4rg9b",
        "colab_type": "text"
      },
      "source": [
        "## 합성곱 계층(Convolutional Layer)\n",
        "\n",
        "위 그림의 필기체나 MNIST 데이터 같은 이미지 데이터는 일반적으로 채널, 세로, 가로 이렇게 3차원으로 구성된 데이터이다. Affine 계층에서는 이 3차원 데이터를 1차원 데이터(784=28*28)로 바꿔 입력했지만 합성곱에서는 3차원 데이터(1, 28, 28)를 입력하고 3차원의 데이터로 출력하므로 형상을 유지할 수 있다. CNN에서는 이러한 입출력 데이터를 특징맵(Feautre Map)이라고한다.\n",
        "\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F23027B3E58F473020771F2\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k172mxmhuzd6",
        "colab_type": "text"
      },
      "source": [
        "### 합성곱 계층 - 연산\n",
        "\n",
        "데이터와 필터의 모양을 (높이, 너비)로 나타내고, 윈도우(Window)라고 부른다. 여기서 입력데이터는 (4, 4), 필터는 (3, 3)이고, 필터가 바로 Conv Layer의 가중치에 해당한다. \n",
        "\n",
        "합성곱 연산은 필터의 윈도우를 일정한 간격으로 이동해가며 계산한다. 즉, 합성곱 연산은 입력데이터와 필터간에 서로 대응하는 원소끼리 곱한 후 총합을 구하게 되며, 이것을 단일 곱셈-누산 Fused Multiply-Add(FMA)라고한다.\n",
        "\n",
        "마지막으로 편향은 필터를 적용한 후에 더해주게 된다.\n",
        "\n",
        "그리고 그 결과를 출력의 해당 장소에 저장한다. 이 과정을 모든 장소에서 수행하면 합성곱 연산의 출력이 완성된다.\n",
        "\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile3.uf.tistory.com%2Fimage%2F2764173558F475B42C0A8B\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy4FJmccuzjc",
        "colab_type": "text"
      },
      "source": [
        "### 합성곱 계층 - 패딩(Padding)\n",
        "\n",
        "패딩(Padding)은 합성곱 연산을 수행하기 전, **입력데이터 주변을 특정값**으로 채워 늘리는 것을 말한다. 패딩(Padding)은 주로 출력데이터의 공간적(Spatial)크기를 조절하기 위해 사용한다. 패딩을 할때, 채울 값은 hyperparameter로 어떤 값을 채울지 결정할 수 있다. 주로 zero-padding을 사용한다.\n",
        "<br>\n",
        "<br>\n",
        "패딩을 적용하는 이유는 출력의 크기를 조절하기 위함이다. 패딩 없이 입력 데이터에 필터를 씌워 합성곱 연산을 수행하면 출력 데이터는 입력 데이터에 비해 무조건 작아지게 되어있다. 합성곱 연산을 반복하면 어느 시점에서는 출력 크기가 1이 되고, 더이상 합성곱 연산을 수행할 수 없게 된다. 이러한 사태를 방지하기 위해 패딩을 사용하는 것이다. 패딩을 사용하면 출력 데이터의 크기를 입력 데이터의 크기와 동일하게 설정할 수 있다. 즉, 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있는 것이다.\n",
        "<br>\n",
        "<br>\n",
        "<IMG SRC=\"https://t1.daumcdn.net/cfile/tistory/99F52B4F5AAD328114?download\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJMGw1Rruz2V",
        "colab_type": "text"
      },
      "source": [
        "### 합성곱 계층 - 스트라이드(Stride)\n",
        "\n",
        "스트라이드는 입력데이터에 필터를 적용할 때 이동할 간격을 조절하는 것, 즉 필터가 이동할 간격을 말한다. 스트라이드 또한 출력 데이터의 크기를 조절하기 위해 사용한다. 스트라이드(Stride)는 보통 1과 같이 작은 값이 더 잘 작동하며, Stride가 1일 경우 입력 데이터의 spatial 크기는 pooling 계층에서만 조절하게 할 수 있다.\n",
        "<br>\n",
        "<br>\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/996F93495AAD356110?download\">\n",
        "<br>\n",
        "<br>\n",
        "- 스트라이드를 키우면 출력 크기는 작아진다.\n",
        "- 패딩을 크게 하면 출력은 크기가 커진다.\n",
        "- 필터의 각 원소 값은 학습을 통해 딥러닝 모델이 알아서 갱신해주는 값이지만, 필터의 크기나 패딩 및 스트라이드의 크기는 모델을 구성할 때 사람이 직접 지정해주어야 하는 초매개변수(hyper-parameter)이다. 이에 대한 완벽한 정답은 없으며, 이미지의 복잡도나 크기 등 다양한 변수에 따라 달라진다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-qFyvd-uzv9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnwezInU41Nn",
        "colab_type": "text"
      },
      "source": [
        "### 3. 풀링 계층 (Pooling Layer)\n",
        "\n",
        "풀링계층은 합성곱 계층의 패딩과 스트라이드처럼 데이터의 공간적 크기를 축소하는데 사용한다. \n",
        "\n",
        "주로 합성곱 계층(Conv Layer)에서 출력데이터의 크기를 입력데이터의 크기 그대로 유지하고, 풀링계층(Pool 에서만 크기를 조절한다. 풀링에는 Max-Pooling과 Average pooling이 있는데 Max-Pooling은 해당영역에서 최대값을 찾는 방법이고, Average-Pooling은 해당영역의 평균값을 계산하는 방법이다. 이미지 인식 분야에서는 주로 Max-Pooling을 사용한다. \n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/2366B34458F47D7808?download\">\n",
        "\n",
        "\n",
        "위의 그림은 2X2 최대 풀링을 스트라이드 2로 처리하는 순서이다. 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "#### 풀링 계층의 특징\n",
        "\n",
        " - 풀링 계층은 합성곱 계층과 달리 학습해야 할 매개변수가 없다. 풀링은 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없다.\n",
        "\n",
        " - 풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 보낸다. 풀링은 2차원 데이터의 크기를 줄이는 연산이므로 3차원을 결정하는 채널 수는 건드리지 않는다. 따라서 채널마다 독립적으로 계산한다.\n",
        "\n",
        " - 풀링 계층은 입력의 변화에 영향을 적게 받는다. 입력 데이터가 조금 변하더라도 풀링 계층 자체가 그 변화를 흡수하여 사라지게 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vbg3St441oG",
        "colab_type": "text"
      },
      "source": [
        "> **요약하자면? CNN은?**\n",
        "<BR><BR>\n",
        " CNN에서는 입력 및 출력 부분에서 뉴런들이 느슨하게 연결되어 있다. 이러한 구조적 특징에 의해 CNN은 DFN이나 RNN에 비해 **학습해야하는 가중치의 수가 적으며**, 이 덕분에 **학습 및 예측이 빠르다는 장점**이 있다. 최근에는 CNN의 강력한 예측 성능과 계산상의 효율성을 바탕으로 이미지뿐만 아니라 시계열 데이터에도 CNN을 적용하는 연구가 활발히 진행되고 있다.\n",
        "<BR><BR>\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbkAuba%2Fbtqz8ZmFQHO%2FxcqkfX6cCu0flJq8RKo7Ak%2Fimg.png\">\n",
        "<BR>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Ym3IHfuZr4",
        "colab_type": "text"
      },
      "source": [
        "# [2] Graph Convolution Network (GCN) / 그래프 합성곱 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8R0FqDY9pbM",
        "colab_type": "text"
      },
      "source": [
        "### CNN → GNN \n",
        "> 이미지에 대한 CNN 연산을 그래프에 대해 적용하면 GCN 이 된다.\n",
        "\n",
        "\n",
        "1. 그래프 데이터 \n",
        "\n",
        "대부분의 머신 러닝 알고리즘은 입력 데이터가 유클리드 공간 (Euclidean space)에 존재함을 가정하고 있다. *모든 입력데이터는 반드시 벡터 또는 행렬의 형태로 표현될 수 있어야 함* \n",
        " 그러나 소셜 네트워크, 관계형 데이터베이스, 분자 구조 등과 같은 데이터들은 Euclidean space에 표현이 불가능한 그래프의 형태로 나타나기 때문에 그래프 데이터 처리를 위한 새로운 인공신경망이 필요했다. 이러한 문제점을 해결하기 위해 제안된 개념이 graph neural network (GNN)이다.\n",
        " GNN을 구현하는 것에는 다양한 방법이 존재할 수 있지만, 가장 많이 이용되는 것은 **spectral graph theory를 기반으로 설계된 Graph Convolutional Network (GCN)**이다.\n",
        "<br>\n",
        "<br>\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2Fbg6MGb%2Fbtqz7zAi83h%2FTKVbgxy7k8qnMIBqKRDvYk%2Fimg.png\">\n",
        "- 소셜 네트워크: 사용자는 node로 표현되며, 친구 관계에 있는 사용자은 edge로 연결된다.\n",
        "- 관계형 데이터베이스: 하나의 데이터베이스 또는 테이블은 node로 표현되며, 데이터간의 연관성이 있거나 쿼리를 처리하기 위해 참조해야하는 데이터베이스 또는 테이블은 edge로 연결된다.\n",
        "- 분자 구조: 각 원자는 node로 표현되며, 결합된 원자들 사이에는 결합을 나타내는 edge가 추가된다.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FckSWPp%2FbtqAcbmi8yT%2FruOK2cWNQjbV15azaH8Mvk%2Fimg.png\">\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "이러한 형태의 그래프 데이터는 유클리드 공간에 존재하지 않으며, 직접적인 방식으로 벡터의 형태로 변환하는 것 또한 불가능하다. 따라서, 벡터 형태의 입력 데이터를 가정하는 기존의 인공신경망 (Artificial Neural Network, ANN)으로는 분자 구조와 같은 그래프 형태의 데이터를 처리할 수 없다는 문제점이 존재한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLgnn02d9pjv",
        "colab_type": "text"
      },
      "source": [
        "2. 이미지 데이터와 합성곱 (Convolution)\n",
        "\n",
        "\n",
        "이미지 데이터는 그림 2와 같이 node 간의 연결이 규칙적이고, 각 node의 feature는 RGB로 표현되는 색상 코드인 그래프로 볼 수 있다.\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FC1o5u%2Fbtqz5bf9ItC%2FOowmk84Ykjuc3uEHYVkiA0%2Fimg.png\">\n",
        "\n",
        "이미 오래전부터 머신 러닝 분야에서는 이미지 데이터를 효과적으로 처리하기 위한 여러 방법들이 연구되어왔으며, 그 중에서도 convolution을 이용한 인공신경망인 합성곱 신경망 (Convolutional Neural Network, CNN)은 매우 뛰어난 성능을 보여주었다. 일반적인 벡터 형태의 데이터가 아닌, 이미지 데이터에서는 각 픽셀들의 위치가 그 자체로 매우 중요한 정보이기 때문에 데이터의 구조를 고려하는 것이 매우 중요하다. CNN은 이러한 이미지 데이터의 특성을 반영하기 위해 convolution을 이용하여 데이터의 구조를 고려한 분류 및 예측을 가능하게 만들었다.\n",
        "\n",
        "데이터의 구조를 고려해야 한다는 점은 이미지뿐만 아니라 그래프 데이터에서도 매우 중요하기 때문에 이미지에 대한 convolution을 일반화하여 그래프 데이터에 적용하기 위한 연구가 머신 러닝 분야에서 활발히 진행되었다. 그래프 합성곱 신경망 (Graph Convolutional Network, GCN)은 **이미지에 대한 convolution을 그래프 데이터로 확장한 머신 러닝 알고리즘이다.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcI72f669psi",
        "colab_type": "text"
      },
      "source": [
        "### GCN의 구조\n",
        "\n",
        "GCN은 일반적으로 graph convolution으로 정의되는 graph convolution layer와 fully-connected layer로 구성된다.\n",
        "<br>\n",
        "<br>\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2Fc1644Y%2Fbtqz6g9DDpP%2FYUxHm1piMVukC115s1R5S0%2Fimg.png\">\n",
        "<br>\n",
        "<br>\n",
        "GCN에서 가장 중요한 부분은 **Graph convolution layer**이다. Graph convolution layer를 통해 그래프 형태의 데이터는 행렬 형태의 데이터로 변환되기 때문에 graph convolution layer를 거친 그래프 형태의 데이터는 기존의 머신 러닝 알고리즘을 그대로 적용할 수 있게 변환된다.\n",
        "<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynayhdWlDBwg",
        "colab_type": "text"
      },
      "source": [
        " ### 그래프 합성곱 계층 (Graph convolution layer)\n",
        "- GCN에서는 **graph convolution을 이용하여 그래프에 포함된 node나 그래프 자체를 벡터 형태의 데이터로 변환**한다.\n",
        "\n",
        "- 기본적인 GCN에서는 node의 feature만을 고려한다.(↔ edge feature) \n",
        "\n",
        "- 그래프는 G=(A,X)와 같이 정의되며, A∈RN×N는 각 node의 연결을 나타내는 인접 행렬 (Adjacency matrix)이고 X∈RN×d는 node feature matrix이다. 이 때, N은 그래프에 포함된 node의 수, d는 node feature vector의 차원 (node feature의 수)이다.\n",
        "\n",
        "**1단계**\n",
        "노드 4개로 구성된 (undirected, unweighted)그래프에서 인접행렬(A 및 A~)과 degree 행렬(D 및 D ~)을 얻을 수 있다.\n",
        "\n",
        "<img src=\"https://baekyeongmin.github.io/images/GCN/gcn_1.png\">\n",
        "\n",
        "**2단계**\n",
        " D~ −12A~D ~−12를 계산하면 아래와 같은데, 각 노드에 연결된 edge의 갯수에 따라 인접행렬(A)을 정규화(normalization)한다. 이는 학습을 진행할 때, 각 노드별 edge의 갯수에 관계없이 모든 노드들을 잘 학습하기 위한 과정으로 볼 수 있다.\n",
        "\n",
        " <img src=\"https://baekyeongmin.github.io/images/GCN/gcn_2.png\">\n",
        "\n",
        "**3단계**\n",
        " 2번 과정에서 계산한 D~−12A~D~−12를 이용하여 D~−12A~D~−12H(l),l=0를 계산하면 아래 그림과 같다.. 여기서 Hl은 l번째(이전 레이어의) hidden state이고, l=0인 경우 초기 값은 각 노드의 초기 feature vector가 된다. 예시로 각 노드가 특정 단어인 경우 word embedding vector를, 각 노드가 문서인 경우 bag-of-word vector를, 가장 간단하게는 전체 노드 개수의 길이를 갖는 one-hot vector를 이용할 수도 있다. 이 식을 계산하면, 각 행은 각 노드에 연결된 노드들(자기자신을 포함한)의 초기 feature 값들(or 이전 hidden state)들의 가중 합이 된다.(가중치는 2번과정에서 계산한 각 노드별 edge개수에 따라 normalize된 값.)\n",
        "\n",
        "<img src=\"https://baekyeongmin.github.io/images/GCN/gcn_3.png\">\n",
        "\n",
        "**4단계**\n",
        "3번과정의 결과물과 학습가능한 parameter W(l)을 곱합니다. 이를 통해 아래 그림과 같이 각 노드별로 인접 노드들의 가중치 * 초기 feature vector * W의 합을 갖게 된다. *결과적으로 GCN은 특정 노드의 representation으로 해당 노드에 연결되어 있는 노드들을 가중합하는 방법*이다.\n",
        "\n",
        "<img src=\"https://baekyeongmin.github.io/images/GCN/gcn_4.png\">\n",
        "\n",
        "**5단계**\n",
        "마지막으로 4번 결과물을 비선형함수(σ)를 통해 비선형성을 학습할 수 있도록 한다.\n",
        "\n",
        "이 layer가 하나일 때는 각 노드들의 인접한 노드들만 이용하여 hidden state를 계산합니다. 하지만 이 layer를 K 개 쌓으면, 해당 노드에서 K개 떨어져 있는(K개의 edge를 갖는) 노드 까지 이용한 hidden state를 계산할 수 있다. 이를 통해, label이 있는 노드가 적더라도, 해당 노드에서 K개 떨어져있는 노드까지 고려하여 학습을 진행할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIQ0af6HSca",
        "colab_type": "text"
      },
      "source": [
        "### 그래프의 표현\n",
        "> 그래프를 인접 행렬(Adjacency Matrix) 또는 인접 리스트(Adjacency List)로 표현할 수 있다.\n",
        "\n",
        "#### 1. 인접 행렬\n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99D211335B90DB8F16\">\n",
        "\n",
        "인접행렬은 2차원 배열(v x v)로 표현될 수 있습니다. 엣지가 존재하는 노드의 짝(i, j)의 배열 값을 1로 설정하고, 엣지가 존재하지 않는 노드의 짝(i, j)의 배열 값을 0으로 설정합니다.가중치 그래프(Weighted Graph)에서는 배열 값을 w(가중치)로 설정 할 수 있습니다.\n",
        "\n",
        "#### 2. 인접 리스트\n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/995CAC335B90DB8F22\">\n",
        "\n",
        "각 꼭짓점(vertex)의 리스트는 헤더(Header)노드를 가집니다. 각 헤더노드들은 배열을 이용하여 연결된 각각의 노드를 순차적으로 가리킵니다.(오름차순)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9lk3vdPDB-o",
        "colab_type": "text"
      },
      "source": [
        " ### 리드아웃 (Readout)\n",
        " 노드 순서에 따라 값의 변동이 있을 수 있기 때문에 설정 해준다.\n",
        "\n",
        " Readout은 graph convolution layer를 통해 생성된 latent feature matrix를 그래프 전체를 표현하는 하나의 벡터로 변환하는 함수이다. 일반적으로 readout은 전체 node의 latent feature vector를 평균내어 그래프 전체를 표현하는 하나의 벡터를 생성한다. Graph classification/regression에서는 readout이 필수적이지만, node classification이나 link prediction에서는 readout이 없는 구조를 이용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1QEW6OauZpe",
        "colab_type": "text"
      },
      "source": [
        "> ## 참고자료<br>\n",
        "https://sacko.tistory.com/17?category=632408<br>\n",
        "https://untitledtblog.tistory.com/1504<br>\n",
        "https://excelsior-cjh.tistory.com/79 <br>\n",
        "https://heung-bae-lee.github.io/categories/deep-learning/<br>\n",
        "https://wikidocs.net/24987<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5PRN-YzuZoN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0iAmCQbPvkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _numerical_gradient_1d(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 값 복원\n",
        "        \n",
        "    return grad\n",
        "\n",
        "\n",
        "def numerical_gradient_2d(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return _numerical_gradient_1d(f, X)\n",
        "    else:\n",
        "        grad = np.zeros_like(X)\n",
        "        \n",
        "        for idx, x in enumerate(X):\n",
        "            grad[idx] = _numerical_gradient_1d(f, x)\n",
        "        \n",
        "        return grad\n",
        "\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 값 복원\n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def identity_function(x):\n",
        "    return x\n",
        "\n",
        "\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))    \n",
        "\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
        "    \n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def relu_grad(x):\n",
        "    grad = np.zeros(x)\n",
        "    grad[x>=0] = 1\n",
        "    return grad\n",
        "    \n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "\n",
        "def mean_squared_error(y, t):\n",
        "    return 0.5 * np.sum((y-t)**2)\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "\n",
        "def softmax_loss(X, t):\n",
        "    y = softmax(X)\n",
        "    return cross_entropy_error(y, t)\n",
        "\n",
        "\n",
        "\n",
        "def _numerical_gradient_1d(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 값 복원\n",
        "        \n",
        "    return grad\n",
        "\n",
        "\n",
        "def numerical_gradient_2d(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return _numerical_gradient_1d(f, X)\n",
        "    else:\n",
        "        grad = np.zeros_like(X)\n",
        "        \n",
        "        for idx, x in enumerate(X):\n",
        "            grad[idx] = _numerical_gradient_1d(f, x)\n",
        "        \n",
        "        return grad\n",
        "\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 값 복원\n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}