{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks(신경망).ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOQmptlvM5i3I7Z9x3D99nW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Deeplearning/blob/master/Neural_Networks(%EC%8B%A0%EA%B2%BD%EB%A7%9D).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdT0Rd3suZXl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#지도학습 알고리즘 : Neural Networks(신경망)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7iDWVx4uZaD",
        "colab_type": "text"
      },
      "source": [
        "<b>What is this?</b>\n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/proxy/v5Xg1L5jbb075BVkOg7-04NZ81PbLOa1hbUu93wPt7IIH8C0vaPprh7aNVzJOXDXn4vcB-7dLFpCX1dY8dfUeE6RQpAqfRHnZ5MzMaiDD9MtiJ18KFOaxI8CJngZTU3kmvWG0akP893TJx1woHjcH-syf7YP0iZzW4wX0A\">\n",
        "\n",
        "\n",
        "인간의 두뇌는 약 800억 개의 뉴런으로 이뤄진 네트워크이며, 그 덕분에 우리가 예전에 봤던 것과는 다른 형태로 표현된 객체도 인식할 수 있다. 이러한 뉴런들의 상호작용으로 입력 신호(기린의 사진)를 레이블(기린)로 변환하며, **신경망(neural networks)**은 이러한 원리를 바탕으로 착안됐다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgPeTDGTuZcz",
        "colab_type": "text"
      },
      "source": [
        "## 0. 도입 : 신경망이 최근 큰 인기를 끄는 핵심적인 이유?\n",
        "- 데이터 저장과 공유 방식의 진보\n",
        "- 컴퓨팅 파워 증가. 중앙 처리 장치(CPU)보다 150배 빠른 **그래픽 처리 장치(GPU)**는 원래 게임 분야에서 고품질 컴퓨터 이미지를 표현하기 위해 사용됐지만, 대규모 데이터 세트를 이용해 신경망을 학습할 때 중요한 엔진 역할을 할 수 있다는 것이 밝혀짐\n",
        "- 개선된 알고리즘. 기계가 인간 두뇌의 성능을 따라잡는 일은 지금까지 난제로 남아 있었지만, 그 성능을 크게 향상시킬 수 있는 여러 가지 기법이 개발됨\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3_m1lJuZgG",
        "colab_type": "text"
      },
      "source": [
        "## 1. 신경망을 학습하는 방법\n",
        "데이터 : MNIST 에서 제공하는 수기 숫자 이미지를 학습 데이터로 사용한다. 신경망은 어떻게 학습하는 것일까?\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Kofi_Appiah/publication/252028600/figure/fig2/AS:298067136925718@1448076151592/Some-samples-of-the-MNIST-database.png\">\n",
        "\n",
        "\n",
        "기계가 이미지를 읽으려면 우선 픽셀로 변환해야 한다. 검은 픽셀은 '0'으로, 흰색 픽셀은 '1'로 표현한다. 이미지가 컬러 이미지라면 적색과 녹색, 청색(RGB)의 색조값을 이용할 수 있다.\n",
        "<img src=\"https://static.javatpoint.com/tutorial/tensorflow/images/mnist-dataset-in-cnn3.png\">\n",
        "\n",
        "이미지를 양자화한 후 신경망에 전달한다. 네트워크에 수기 숫자 이미지와 각 이미지가 나타내는 실제 숫자의 레이블을 함께 제공한다. 이렇게 이미지와 그에 상응하는 레이블을 학습시킨 후, 레이블이 없는 새로운 이미지를 인식하는지 테스트 한다. 물론 '3','5'를 혼동하기도 하고, '2'와 '7','8'을 오인식하는 오류를 범하기도 하나, 그럼에도 불구하고 **신경망은 전체적인 정확도를 유지함과 동시에 사람보다 훨씬 빠르게 동작한다.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTPG72BquZjs",
        "colab_type": "text"
      },
      "source": [
        "## 2. 신경망의 구성 요소\n",
        "수기 숫자를 인식하기 위해 신경망은 뉴런으로 이뤄진 여러 레이어를 거쳐 이미지를 처리하고 예측 결과를 계산한다. 일반적인 신경망 구성은 다음과 같다.\n",
        "\n",
        "- 입력 계층 : 입력된 이미지의 모든 픽셀을 처리하는 레이어. **이미지에 포함된 뉴런의 개수와 같은 수의 뉴런을 포함**한다. 더 나은 예측을 위해 컨볼루션 레이어를 사용할 수 있다. 각 픽셀을 따로 처리하는 대신, 컨볼류션 레이어는 픽셀의 조합을 바탕으로 특징을 찾는다. 예를 들어, 숫자 '6'에는 원이나 위쪽을 향하는 꼬리 모양이 존재한다. 이러한 분석 방식의 특징은 위치가 아니라 존재 여부에만 의존적이므로 핵심적인 특징이 가운데에서 빗겨나 존재해도 신경망이 숫자를 인식할 수 있다. 이러한 성질을 일컬어 위치 불변성(translational invariance)라고 한다.\n",
        "\n",
        "- 은닉 레이어(hidden layer) : 픽셀이 신경망에 입력된 후, 여러 레이어를 거쳐 네트워크가 각 레이블에 대해 예전에 학습했던 이미지와의 유사성을 계산하는 변환을 수행한다.좀 더 높은 정확도를 위해 더 많은 변환을 사용할 수 있지만, 처리 시간이 길어진다. 하지만 일반적으로 적은 수의 레이어만으로도 충분하다. 각 레이어의 뉴런 개수는 이미지에 포함된 픽셀 개수에 비례해야 한다. \n",
        "\n",
        "- 출력 레이어 : 최종 예측을 표현하는 레이어로써 가능한 출력의 개수에 따라 하나 또는 그 이상의 뉴런으로 구성된다. \n",
        "\n",
        "- 손실 레이어(loss layer) : 신경망을 학습시키는 동안에는 손실 레이어가 필요하다. 일반적으로 끝에 위치하며, 입력이 제대로 인식됐는지의 여부에 따라 오차의 정도에 대한 피드백을 출력한다.\n",
        "\n",
        "손실 레이어는 신경망 학습에서 핵심적인 역할을 한다. 올바른 예측을 한 경우에는 손실 계층의 피드백으로 인해 예측에 영향을 미친 활성화 경로상의 뉴런을 강화한다. 잘못된 예측을 한 경우, 활성화 경로상의 뉴런으로 오차가 전달돼 오차를 줄이는 방향으로 활성화 기준을 재조정한다. 이런 과정을 **역전파(backpropagation)** 라고 한다.\n",
        "<img src=\"https://i.stack.imgur.com/H1KsG.png\">\n",
        "\n",
        "**이러한 반복적인 학습 과정에서 신경망은 입력 신호와 올바른 출력 레이블 사이의 연관 관계를 학습하며, 학습된 연관 관계는 각 뉴런에 활성화 규칙(activation rule)이라는 형태로 프로그래밍된다. *따라서 신경망의 정확도를 높이려면 활성화 규칙에 영향을 미치는 구성 요소를 튜닝해야 한*다.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKT8BK4uZu2",
        "colab_type": "text"
      },
      "source": [
        "## 3. 활성화 규칙\n",
        "활성화 규칙이란, 뉴런이 활성화되는 데 필요한 입력 신호의 출처와 강도를 규정한다. 신경망 학습 과정에서 이 규칙이 미세하게 튜닝된다. 학습이 진행되면서 레이어간 연관돼 있다는 것을 학습한다. 연관 관계는 강도가 각기 다른데, 그 강도를 가중값이라 하고 w로 표기한다. 이 연관 관계에는 방향성이 있다. 예를 들어 가중값이 -1 이라면 전달되는 입력 신호는 감소한다.\n",
        "\n",
        "즉, 활성화 activation란 말 그대로 입력신호의 총합이 활성화를 일으킬지 정하는 역할을 한다. 그 정하는 것을 하는 내용들이 함수 안에 담겨 있는 것이다. ( = 출력값을 반환하기 위해 무언가를 처리해주는 변환기)\n",
        "\n",
        "#### 계단함수 (step function)\n",
        "퍼셉트론(단층 퍼셉트론)은 활성화 함수로 step function(계단 함수)를 이용한다. 특정 임계값을 넘기면 활성화되는 함수이다. 아래 왼쪽(a)가 계단 함수이다. 0에서 멈추어있다. 어느 기점에서 1로 바뀐다. (Input의 값이 weight와 계산하여 다 더하고 사전에 설정한 임계값(threshold)과 비교해서 임계값을 넘으면 Output으로 1을 출력하고, 0을 출력했다.)\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Raja_Ali5/publication/306038981/figure/fig14/AS:393836095393798@1470909250163/Figure-3-Two-basic-activation-functions-a-Step-Function-b-Sigmoid-Function.ppm\">\n",
        "\n",
        "\n",
        "#### 시그모이드 함수 (sigmoid function)\n",
        "신경망에서 주로 이용하는 활성화 함수는 시그모이드 함수이다. 아래는 시그모이드 함수를 나타낸 식이다. e는 자연상수로 2.7192...의 값을 갖는 실수 이다. 계단함수에 비해 완만한 곡선 형태로 비선형이다. 특정 경계를 기준으로 출력이 확 바뀌어버리는 계단함수와는 달리 시그모이드 함수는 완만하게 매끄럽게 변화하는데 이 매끄러움이 신경망 학습에서 중요하며 활성화 함수로 시그모이드 함수를 사용하는 이유이기도 하다.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\">\n",
        "\n",
        "시그모이드 함수는 값을 실수형으로 가지는 것을 볼 수 있다. 시그모이드 함수의 매끄러움은 가중치 값을 전달할 때 좀 더 부드럽게 양을 조절해서 전달할 수 있다는 점이 계단 함수와 다른 점이다. 둘다 비선형인 점은 동일하다.\n",
        "\n",
        "\n",
        "#### ReLU 함수\n",
        "입력이 0을 넘으면 그 입력을 그대로 출력하고 0 이하이면 0을 출력하는 함수이다.\n",
        "\n",
        "\n",
        "\n",
        "#### **왜 비선형 함수를 사용해야 하는가?**\n",
        "선형함수를 사용했을 때는 은닉층을 사용하는 이점이 없기 때문이다. 다시 말해 선형함수를 여러층으로 구성한다 하더라도 이는 선형함수를 세번 연속 반복한 것에 지나지 않는다는 의미와 같기 때문이다. y = ax라는 선형함수가 있다고 한다면 이 것을 3층으로 구성하면 y = a(a(a(x))) 와 동일한 것으로 이는 y = a3(x)와 같다. 굳이 은닉층 없이 선형함수로 네트워크를 구성하는 것은 의미가 없다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUMieUTsuZ1J",
        "colab_type": "text"
      },
      "source": [
        "## 4. 다차원 배열 계산\n",
        "\n",
        "다차원 배열의 계산은 앞서 설명한 가중치의 값을 보다 편하게 하기 위해서 행렬 연산을 이용하는 것이다. 한 두개의 신경망 층은 인간이 계산할 수 있을지 모르겠지만 그 이상의 수 많은 차원의 수많은 뉴런층으로 구성된 신경망의 weight를 일일이 계산하는 것은 불가능한 일이다. 이를 컴퓨팅적으로도 쉽게 할 수 있도록 돕는 것이 행렬 연산이다.(선형대수 개념 학습 필요!)\n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/992F0D3359E6FFD404\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDr30TlyuZ8Q",
        "colab_type": "text"
      },
      "source": [
        "## 5. 출력층 설계\n",
        "신경망은 분류(classification)와 회귀(regression) 문제에 모두 활용할 수 있다. 어떤 문제냐에 따라 활성화 함수가 달라질 뿐이다. 분류는 어떤 사람이 사기를 쳤는지(1), 안 쳤는지(0) 예측하는 것이고, 회귀는 사기당한 금액이 얼마($10,000)였는지 에측하는 문제이다. 둘다 크게 보면 예측(prediction)이다.\n",
        "\n",
        "- 회귀 --> 항등 함수 (출력 값을 그대로 반환하는 함수) identity function\n",
        "- 분류(0/1) --> 시그모이드 함수 sigmoid function\n",
        "- 분류(multiple) --> 소프트맥스 함수 softmax function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU1UekVruaC7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOeHW0VcuaIN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0XAfLxTuZ6g",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ne80qGuZzs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Ym3IHfuZr4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1QEW6OauZpe",
        "colab_type": "text"
      },
      "source": [
        "## 참고자료\n",
        "\n",
        "https://sacko.tistory.com/17?category=632408\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5PRN-YzuZoN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}