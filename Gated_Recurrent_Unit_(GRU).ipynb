{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gated Recurrent Unit (GRU).ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMrQ/c9HDS9IE9c0s5WzZ/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Deeplearning/blob/master/Gated_Recurrent_Unit_(GRU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_r8-DlSY9FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zSgwB65ZAeu",
        "colab_type": "text"
      },
      "source": [
        "# Gated Recurrent Unit (GRU)\n",
        "---\n",
        "GRU(Gated Recurrent Unit) 셀은 2014년에 K. Cho(조경현) 등에 의해 '이 논문'에서 제안된 LSTM 셀의 간소화된 버전이다.\n",
        "\n",
        "> GRU와 LSTM은 인간이 텍스트를 인지하는 구조와 일맥상통한다. 하기와 같은 리뷰를 보았다고 할 때, 무의식적으로 당신의 뇌는 중요한 키워드만 인지하게 된다. \"Amazing\", \"Perfectly balanced breakfast\", \"be buying again\" 이 밖에 \"this\", \"gave\", \"all\"과 같은 단어는 잘 기억하지 못할 것이다. 이 처럼, **LSTM, GRU도 관계없는 데이터는 잊고(forget), 관계있는 데이터만 가지고 make prediction을 한다.**\n",
        "\n",
        "<IMG SRC=\"https://miro.medium.com/max/1050/1*ygAgowqTZjR6ABzZHd8Bqg.gif\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-dz2RtBvtCr",
        "colab_type": "text"
      },
      "source": [
        "## GRU 알고리즘 구조 (vs LSTM)\n",
        "---\n",
        "\n",
        "**[LSTM]** <br>\n",
        "Ct = memory cell<br>\n",
        "Ht = hidden cell<br>\n",
        "1) 앞서 과거 정보를 위한 ft, 현재 정보를 위한 it, gt를 구한 후,<br>\n",
        " 2) (ft○Ct-1)의 계산을 통해 이전 시점의 cell 정보를 얼마나 유지할지를 구하고 <br> 3) (it○gt)를 통해 현재 기억할 정보를 구한다. <br>\n",
        " 4) 마지막으로 ('과거에서 유지할 정보' + '현재에서 유지할 정보')를 통해 현재 시점의 cell state를 update함 <Br>\n",
        " 5) 최종적으로 우리가 출력할 출력값, hidden state는 위와 같은 계산으로 구해집니다. 결국 현 시점의 hidden state는 현 시점의 cell state와 함께 계산되며 출력과 동시에 다음 시점으로 hidden state를 넘김\n",
        "\n",
        "<IMG SRC=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F9905CF385BD5F5EC027F20\">\n",
        "\n",
        "**[GRU]** <br>\n",
        "Ct가 없고 Ht 은닉셀만 있다. Ht가 transfer 역할까지 한다.\n",
        "<IMG SRC=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- LSTM Cell에서의 두 상태 벡터Ct와 ht가 하나의 벡터ht ​로 합쳐졌다.\n",
        "\n",
        "- 리셋게이트 r과 업데이트 게이트z 총 두가지 게이트가 있다. \n",
        "  - **R reset gate** : 과거의 은닉 상태를 얼마나 '무시'할지 정함. 이전 시점의 hidden state와 현 시점의 x를 시그모이드 함수를 적용하여 구하는 방식이다. 0~1사이의 값을 가질 것이며, 이전 hidden state 값을 얼마나 활용할 것인지에 대한 정보로 해석할 수 있다. (만약 r이 0이면, 과거의 은닉상태는 완전히 무시된다.)  reset gate에서 나온 값은 그대로 사용되는 것이 아니라 위에서 (3)번째 ht ~ 식으로 다시 활용한다. \n",
        "\n",
        "  - **Z update gate** : LSTM에서의 forget, input gate를 합친 역할을 하며, 과거와 현재의 정보를 각각 얼마나 반영할지에 대한 비율을 구하는 것이 핵심이다. (1)번째 식을 통해서 구한 결과 z는 현재 정보를 얼마나 사용할지 반영한다.(1-z)는 과거의 정보에 대해 얼마나 사용할지 방녕한다. (4)식을 통해 현 시점의 출력값 hidden state를 계산한다.\n",
        "\n",
        "- 하나의 gate controller가 forget과 input 게이트(gate)를 모두 제어한다.  z가 0을 출력하면 forget 게이트가 열리고 input 게이트가 닫히며, ​가 1일 경우 input 게이트가 열린다. 즉, 이전(​)의 기억이 저장 될때 마다 타임 스텝 ​의 입력은 삭제된다. \n",
        "\n",
        "- GRU 셀은 output 게이트가 없어 전체 상태 벡터 ​가 타임 스텝마다 출력되며, 이전 상태 ​의 어느 부분이 출력될지 제어하는 새로운 gate controller인 ​가 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOSvo4dCZA2o",
        "colab_type": "text"
      },
      "source": [
        "## LSTM 과의 차이점\n",
        "---\n",
        " 게이팅 메커니즘을 통해 긴 시퀀스를 잘 기억하도록 해준다는 점에서는 LSTM과 기본 아이디어가 같지만, 몇 가지 차이점이 있다\n",
        "\n",
        "- GRU는 게이트가 2개이고, LSTM은 3개 (매개변수가 적어서 빠른 스피드, 적은 데이터로도 동작 가능)\n",
        "- GRU는 내부 메모리 값 ( ct )이 외부에서 보게되는 hidden state 값과 다르지 않습니다. LSTM에 있는 출력 게이트가 없기 때문입니다.\n",
        "- 입력 게이트와 까먹음 게이트가 업데이트 게이트 z로 합쳐졌고, 리셋 게이트 r은 이전 hidden state 값에 바로 적용됩니다. 따라서, LSTM의 까먹음 게이트의 역할이 r과 z 둘 다에 나눠졌다고 생각할 수 있습니다.\n",
        "- 출력값을 계산할 때 추가적인 비선형 함수를 적용하지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHqRKqBZA6A",
        "colab_type": "text"
      },
      "source": [
        "## GRU vs LSTM\n",
        "---\n",
        "\n",
        "- **GRU는 상당히 최근 기술이고 (2014), 아직 그 장단점이 확실히 밝혀지지는 않음**\n",
        "- Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling과 An Empirical Exploration of Recurrent Network Architectures 두 논문에서의 실험적인 결과에 따르면, 확실한 승자는 없는 것으로 보임\n",
        "- 많은 문제들에서 두 모델 모두 좋은 성능을 보여주고 있고, **레이어 사이즈같은 파라미터 튜닝을 잘 하는 것이 모델을 고르는 것보다 더 중요**\n",
        "- **GRU는 파라미터 수가 적어서 (U와 W가 더 작다) 학습 시간이 더 짧게 걸리고 보다 적은 데이터로도 학습이 가능**\n",
        "- 반대로 말하면 충분한 수의 데이터가 있을 경우에는 LSTM의 우수한 모델링 파워가 더 좋은 결과를 보여줌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o39x3JkOkkUH",
        "colab_type": "text"
      },
      "source": [
        "## GRU 와 LSTM 활용\n",
        "---\n",
        "\n",
        "- Speech recognition models\n",
        "- Text generation\n",
        "- Generate captions for video\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePbgaserjtsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import theano as theano\n",
        "import theano.tensor as T\n",
        "from theano.gradient import grad_clip\n",
        "import time\n",
        "import operator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpbHTL8vjuVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUTheano:\n",
        "    \n",
        "    def __init__(self, word_dim, hidden_dim=128, bptt_truncate=-1):\n",
        "        # Assign instance variables\n",
        "        self.word_dim = word_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bptt_truncate = bptt_truncate\n",
        "        # Initialize the network parameters\n",
        "        E = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim))\n",
        "        U = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (6, hidden_dim, hidden_dim))\n",
        "        W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (6, hidden_dim, hidden_dim))\n",
        "        V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
        "        b = np.zeros((6, hidden_dim))\n",
        "        c = np.zeros(word_dim)\n",
        "        # Theano: Created shared variables\n",
        "        self.E = theano.shared(name='E', value=E.astype(theano.config.floatX))\n",
        "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
        "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
        "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
        "        self.b = theano.shared(name='b', value=b.astype(theano.config.floatX))\n",
        "        self.c = theano.shared(name='c', value=c.astype(theano.config.floatX))\n",
        "        # SGD / rmsprop: Initialize parameters\n",
        "        self.mE = theano.shared(name='mE', value=np.zeros(E.shape).astype(theano.config.floatX))\n",
        "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
        "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
        "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
        "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
        "        self.mc = theano.shared(name='mc', value=np.zeros(c.shape).astype(theano.config.floatX))\n",
        "        # We store the Theano graph here\n",
        "        self.theano = {}\n",
        "        self.__theano_build__()\n",
        "    \n",
        "    def __theano_build__(self):\n",
        "        E, V, U, W, b, c = self.E, self.V, self.U, self.W, self.b, self.c\n",
        "        \n",
        "        x = T.ivector('x')\n",
        "        y = T.ivector('y')\n",
        "        \n",
        "        def forward_prop_step(x_t, s_t1_prev, s_t2_prev):\n",
        "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
        "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))\n",
        "            \n",
        "            # Word embedding layer\n",
        "            x_e = E[:,x_t]\n",
        "            \n",
        "            # GRU Layer 1\n",
        "            z_t1 = T.nnet.hard_sigmoid(U[0].dot(x_e) + W[0].dot(s_t1_prev) + b[0])\n",
        "            r_t1 = T.nnet.hard_sigmoid(U[1].dot(x_e) + W[1].dot(s_t1_prev) + b[1])\n",
        "            c_t1 = T.tanh(U[2].dot(x_e) + W[2].dot(s_t1_prev * r_t1) + b[2])\n",
        "            s_t1 = (T.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev\n",
        "            \n",
        "            # GRU Layer 2\n",
        "            z_t2 = T.nnet.hard_sigmoid(U[3].dot(s_t1) + W[3].dot(s_t2_prev) + b[3])\n",
        "            r_t2 = T.nnet.hard_sigmoid(U[4].dot(s_t1) + W[4].dot(s_t2_prev) + b[4])\n",
        "            c_t2 = T.tanh(U[5].dot(s_t1) + W[5].dot(s_t2_prev * r_t2) + b[5])\n",
        "            s_t2 = (T.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev\n",
        "            \n",
        "            # Final output calculation\n",
        "            # Theano's softmax returns a matrix with one row, we only need the row\n",
        "            o_t = T.nnet.softmax(V.dot(s_t2) + c)[0]\n",
        "\n",
        "            return [o_t, s_t1, s_t2]\n",
        "        \n",
        "        [o, s, s2], updates = theano.scan(\n",
        "            forward_prop_step,\n",
        "            sequences=x,\n",
        "            truncate_gradient=self.bptt_truncate,\n",
        "            outputs_info=[None, \n",
        "                          dict(initial=T.zeros(self.hidden_dim)),\n",
        "                          dict(initial=T.zeros(self.hidden_dim))])\n",
        "        \n",
        "        prediction = T.argmax(o, axis=1)\n",
        "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
        "        \n",
        "        # Total cost (could add regularization here)\n",
        "        cost = o_error\n",
        "        \n",
        "        # Gradients\n",
        "        dE = T.grad(cost, E)\n",
        "        dU = T.grad(cost, U)\n",
        "        dW = T.grad(cost, W)\n",
        "        db = T.grad(cost, b)\n",
        "        dV = T.grad(cost, V)\n",
        "        dc = T.grad(cost, c)\n",
        "        \n",
        "        # Assign functions\n",
        "        self.predict = theano.function([x], o)\n",
        "        self.predict_class = theano.function([x], prediction)\n",
        "        self.ce_error = theano.function([x, y], cost)\n",
        "        self.bptt = theano.function([x, y], [dE, dU, dW, db, dV, dc])\n",
        "        \n",
        "        # SGD parameters\n",
        "        learning_rate = T.scalar('learning_rate')\n",
        "        decay = T.scalar('decay')\n",
        "        \n",
        "        # rmsprop cache updates\n",
        "        mE = decay * self.mE + (1 - decay) * dE ** 2\n",
        "        mU = decay * self.mU + (1 - decay) * dU ** 2\n",
        "        mW = decay * self.mW + (1 - decay) * dW ** 2\n",
        "        mV = decay * self.mV + (1 - decay) * dV ** 2\n",
        "        mb = decay * self.mb + (1 - decay) * db ** 2\n",
        "        mc = decay * self.mc + (1 - decay) * dc ** 2\n",
        "        \n",
        "        self.sgd_step = theano.function(\n",
        "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
        "            [], \n",
        "            updates=[(E, E - learning_rate * dE / T.sqrt(mE + 1e-6)),\n",
        "                     (U, U - learning_rate * dU / T.sqrt(mU + 1e-6)),\n",
        "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-6)),\n",
        "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-6)),\n",
        "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-6)),\n",
        "                     (c, c - learning_rate * dc / T.sqrt(mc + 1e-6)),\n",
        "                     (self.mE, mE),\n",
        "                     (self.mU, mU),\n",
        "                     (self.mW, mW),\n",
        "                     (self.mV, mV),\n",
        "                     (self.mb, mb),\n",
        "                     (self.mc, mc)\n",
        "                    ])\n",
        "        \n",
        "        \n",
        "    def calculate_total_loss(self, X, Y):\n",
        "        return np.sum([self.ce_error(x,y) for x,y in zip(X,Y)])\n",
        "    \n",
        "    def calculate_loss(self, X, Y):\n",
        "        # Divide calculate_loss by the number of words\n",
        "        num_words = np.sum([len(y) for y in Y])\n",
        "        return self.calculate_total_loss(X,Y)/float(num_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4teww2cxjtQX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnAGTw88ZA9i",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7BuCQPZZBAc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}