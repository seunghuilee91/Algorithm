{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN , DCGAN",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOkdUw/d8BIIvC4RSSYlx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Deeplearning/blob/master/GAN_%2C_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcr706zLSvK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flCiVxmYS_t8",
        "colab_type": "text"
      },
      "source": [
        "# GAN (Generative Adversarial Network, 2014)\n",
        "---\n",
        "\n",
        "- 생성 모델\n",
        "- 기존의 어떤 방식보다 사실적인 결과를 만들어 내는 점에 엄청난 평가\n",
        "- Discriminator(판별기)와 Generator(생성기)가 경쟁적으로 대립시켜(Adversarial) 학습\n",
        "- 한번씩 교차로 학습\n",
        "> GAN에서는 단순히 하나를 학습하기보다 경쟁시켜 학습하기 때문에 **판별기와 생성기가 함께 성장**. \n",
        "판별기는 이전의 분류모델로, 보통 맞다/아니다의 이진분류를 사용. 다른 모델과 차이점은 분류기의 입력에 생성 모델이 만들어낸 이미지를 사용하는 것임. 그러면, 생성 모델은 분류기가 분류할 이미지를 만들어내기 위해서 노력함. <br><br>\n",
        "즉, **생성모델의 성능이 높아질 수록 분류모델은 어려운 문제를 풀게되고, 성능도 함께 오름**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX3Y6EqsS_7R",
        "colab_type": "text"
      },
      "source": [
        "## 모델 아키텍쳐\n",
        "\n",
        "**[두가지 모델]**\n",
        "- Generator Model : 생성한 데이터를 Discriminator가 진짜로 식하도록 하는 것이 목표\n",
        "\n",
        "- Discriminator Model : Generator로 부터 전달된 데이터를 가짜로 인식하도록 하는 것이 목표\n",
        "\n",
        "\n",
        "<BR>\n",
        "\n",
        "<IMG SRC=\"https://pathmind.com/images/wiki/GANs.png\">\n",
        "\n",
        "\n",
        "**[동작 단계]**\n",
        "\n",
        "1. Generator가 임의의 수를 입력받아 생성한 이미지로 변환한다.\n",
        "\n",
        "2. 이렇게 생성된 이미지는 실제 데이터 세트에서 가져온 이미지들과 함께 Discriminator에게 전달된다.\n",
        "\n",
        "3. Discrminator는 실제 이미지와 가짜 이미지를 판별하여 0과 1사이의 확률 값으로 반환한다. (1은 실제 이미지, 0은 가짜 이미지)\n",
        "\n",
        "> 두 개의 모델을 경쟁을 시켜 최적의 결과 값을 만들어내는 것이다. 제로썸 게임처럼 서로 반대되는 목적함수 또는 손실함수를 통해 최적화하려고 시도 한다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg4PAovdS__J",
        "colab_type": "text"
      },
      "source": [
        " ## 장점 및 한계점\n",
        "\n",
        "**[장점]**\n",
        "1. (압도적인) 생성 모델의 성능\n",
        "\n",
        "2. 분류 모델의 효율적인 학습\n",
        " - 학습데이터가 적어도, 생성모델을 활용하여 보충할 수 있음\n",
        " -분류모델을 더 강인하게 학습할 수 있음\n",
        "\n",
        "3. latent vector (잠재 벡터)\n",
        " - 생성모델의 결과를 다르게할 수 있는 잠재 공간이 있음\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 실제 있을 것 같은 것을 잘만들어낸다'라는 관점에서 보면 충분치 않은 데이터를 가지고 어느 수준의 데이터를 만들어 낼 수 있다.\n",
        "# 보통 AI를 학습시킬 때는 pair의 입력 데이터가 필요한데 pair로 표현할 수 없는 경우가 있을때 GAN을 사용할 수 있다.(ex. 예술작품)\n",
        "# (사용사례1) 가방 스케치만 가지고, 가방을 만들어낼 수 있다.\n",
        "# (사용사례2) 불량 샘플이 필요한 경우 GAN 모델을 통해 몇 개 취득한 불량으로 부터 그 불량의 유형에 해당하는 다양한 케이스를 만들어낼 수 있다. \n",
        "# (사용사례3) 영어를 얘기하면 한국어로 만들어낸다.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "**[한계점]**\n",
        "\n",
        "**1. GAN은 결과가 불안정하다**\n",
        "\n",
        "  - 기존 GAN만 가지고는 좋은 성능이 잘 안나왔다.\n",
        "  - 수렴하지 못하는 경우가 생김\n",
        "  - 생성기와 판별기가 고루 학습이 되어야하는데, 편향적으로 되어버릴 수 있음\n",
        "\n",
        "\n",
        "**2. Black-box method**\n",
        "\n",
        "Neural Network 자체의 한계라고 볼 수 있는데, 결정 변수나 주요 변수를 알 수 있는 다수의 머신러닝 기법들과 달리 Neural Network은 처음부터 끝까지 어떤 형태로 그러한 결과가 나오게 되었는지 그 과정을 알 수 없다.\n",
        "\n",
        "\n",
        "\n",
        "**3. Generative Model 평가**\n",
        "  \n",
        " GAN은 결과물 자체가 새롭게 만들어진 Sample 이다. 이를 기존 sample과 비교하여 얼마나 비슷한 지 확인할 수 있는 정량적 척도가 없고, 사람이 판단하더라도 이는 주관적 기준이기 때문에 얼마나 정확한지, 혹은 뛰어난지 판단하기 힘들다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzXCUX5Sze1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_74oURY5r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "num_epochs = 200\n",
        "batch_size = 100\n",
        "sample_dir = 'samples'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0kgd2UuY5zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image processing\n",
        "# transform = transforms.Compose([\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
        "#                                      std=(0.5, 0.5, 0.5))])\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n",
        "                                     std=[0.5])])\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt05G3PuY53v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "# Generator \n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, image_size),\n",
        "    nn.Tanh())\n",
        "\n",
        "# Device setting\n",
        "D = D.to(device)\n",
        "G = G.to(device)\n",
        "\n",
        "# Binary cross entropy loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JasA9x7AZ2pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start training\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        images = images.reshape(batch_size, -1).to(device)\n",
        "        \n",
        "        # Create the labels which are later used as input for the BCE loss\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Eg701JZ204",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "        # ================================================================== #\n",
        "        #                      Train the discriminator                       #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        # Second term of the loss is always zero since real_labels == 1\n",
        "        \n",
        "        outputs = D(images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "        \n",
        "        # Compute BCELoss using fake images\n",
        "        # First term of the loss is always zero since fake_labels == 0\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        reset_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYdCT23SZ24j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # ================================================================== #\n",
        "        #                        Train the generator                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        \n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
        "                          real_score.mean().item(), fake_score.mean().item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT8AkH6pZ28Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # Save real images\n",
        "    if (epoch+1) == 1:\n",
        "        images = images.reshape(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    # Save sampled images\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCe_E0RkaFvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model checkpoints \n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azcpp95pcvdm",
        "colab_type": "text"
      },
      "source": [
        "# DCGAN (Deep Convolutional GAN, 2015)\n",
        "\n",
        "---\n",
        "\n",
        "- GAN의 불안정성 등의 단점을 극복한 끝판왕, 이 논문 이후에 나오는 대다수의 GAN 구조는 전부 DCGAN의 구조를 사용했다고 해도 무방함 \n",
        "\n",
        "- 의의 : 지도학습(Supervised Learning)에 Convolutional Neural Network (CNN)을 이용 (지도학습에서의 CNN의 성공과 비지도 학습 간의 격차를 줄이는 데에 큰 역할)\n",
        "\n",
        "> DCGAN의 목표\n",
        "1. Generator가 단순 기억으로 generate하지 않는다는 것을 보여줘야 한다. <BR> 2. z의 미세한 변동에 따른 generate결과가 연속적으로 부드럽게 이루어져야 한다(이를 walking in the latent space라고 한다)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fprBl5ccvhA",
        "colab_type": "text"
      },
      "source": [
        "## 모델 아키텍쳐\n",
        "\n",
        "**기존 GAN Architecture** <BR>\n",
        "기존 GAN은 자세히 살펴보면 다음과 같은 아주 간단하게 fully-connected로 연결되어 있다.\n",
        "<IMG SRC=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/gan-architecture.png\">\n",
        "\n",
        "**CNN Architecture** <BR>\n",
        "CNN은 이러한 fully-connected 구조 대신에 convolution, pooling, padding을 활용하여 레이어를 구성한다.\n",
        "\n",
        "<IMG SRC=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/cnn-architecture.png\">\n",
        "\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "---\n",
        "\n",
        "###**DCGAN Architecture** <BR>\n",
        "DCGAN은 결국, 기존 GAN에 존재했던 fully-connected구조의 대부분을 CNN 구조로 대체한 것인데, 앞서 언급했던 것처럼 엄청난 시도들 끝에 다음과 같이 구조를 결정하게 되었다.\n",
        "\n",
        "> - Discriminator에서는 모든 pooling layers를 **strided convolutions** 로 바꾸고, Generator에서는 pooling layers를 **fractional-strided convolutions** 으로 바꾼다.\n",
        "- Generator와 Discriminator에 batch-normalization을 사용한다. 논문에서는 이를 통해 deep generators의 초기 실패를 막는다고 하였다. 그러나 모든 layer에 다 적용하면 sample oscillation과 model instability의 문제가 발생하여 Generator output layer와 Discriminator input layer에는 적용하지 않았다고 한다.\n",
        "- Fully-connected hidden layers를 삭제한다.\n",
        "- Generator에서 모든 활성화 함수를 Relu를 쓰되, 마지막 결과에서만 Tanh를 사용한다.\n",
        "- Discriminator에서는 모든 활성화 함수를 LeakyRelu를 쓴다.\n",
        "\n",
        "<img src=\"https://2.bp.blogspot.com/-oMyhHfxOqiE/WKF4KlVYWJI/AAAAAAAABRs/6BDIypy1hn0U8MGRFxfVaXOcQDO7vX1cQCK4B/s1600/dcgan-architecture.PNG\">\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Batch Normalization**<br>\n",
        " = 배치 정규화는 활성화함수의 활성화값 또는 출력값을 정규화(정규분포로 만든다)하는 작업\n",
        "\n",
        "[장점]\n",
        "- 학습 속도가 개선된다 (학습률을 높게 설정할 수 있기 때문)\n",
        "- 가중치 초깃값 선택의 의존성이 적어진다 (학습을 할 때마다 출력값을 정규화하기 때문)\n",
        "- 과적합(overfitting) 위험을 줄일 수 있다 (드롭아웃 같은 기법 대체 가능)\n",
        "- Gradient Vanishing 문제 해결\n",
        "\n",
        "<img src=\"http://sanghyukchun.github.io/images/post/88-5.png\">\n",
        "\n",
        "**Strided convolutions**\n",
        "\n",
        " ' convolutions는 필터를 거치며 크기가 작아진다\n",
        "<img src=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/padding_strides.gif\">\n",
        "\n",
        "\n",
        "\n",
        "**Fractionally-strided convolutions**\n",
        "\n",
        "'input에 padding을 하고 convolution을 하면서 오히려 크기가 더 커진다.\n",
        "<img src=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/padding_strides_transposed.gif\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw2-yTTLcvkF",
        "colab_type": "text"
      },
      "source": [
        "### **Visualization**\n",
        "**Generated bedrooms**\n",
        "<img src=\"https://4.bp.blogspot.com/-oLa4ynDytNc/WKLIUmTRIjI/AAAAAAAABSg/yK0Zyg7dFAIbjPJvIatke7ZKLUyOeIuBACK4B/s1600/dcgan-fig2.PNG\">\n",
        "▲ 한 번 epoch을 돌려 학습한 후 생성된 침실 사진\n",
        "\n",
        "*앞서 얘기했던 1번 문제(Memorization)가 일어나지 않았다는 것을 검증하기 위해서 네트워크에 학습 데이터(training data)를 한 번만 보여준 결과*\n",
        "\n",
        "<img src=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/visualization-1.png\">\n",
        "\n",
        "▲ 다섯 번 epoch을 돌려 학습한 후 생성된 침실 사진\n",
        "\n",
        "\n",
        "**Walking in the latent space**<br>\n",
        " *DCGAN에서 학습된 Generator의 input인 z값(latent space)을 조금씩 바꿔가면서(walking) 생성되는 output 이미지가 어떻게 바뀌는지를 확인한 그림, 특히 중간에 여섯 번째 줄의 그림들을 보면 벽이었던 곳에서 서서히 커다란 창문이 있는 방으로 바뀌어가는 것을 볼 수 있음.*\n",
        "\n",
        "<img src=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/visualization-2.png\">\n",
        "\n",
        "**Visualize filters (no longer black-box)**\n",
        "<br>\n",
        "*앞서 CNN이 black-box 모델이라 안이 어떻게 돌아가는지 모르고 쓸 뿐이라는 지적받았던 부분을 DCGAN 논문에서는 이 부분을 조금이나마 보여주고자 input까지 backpropagation을 하여 어떤 input이 discriminator가 학습한 feature의 어떤 부분을 active하게 하는지를 보여줌*\n",
        "\n",
        "<img src=\"https://angrypark.github.io/images/2017-08-03-DCGAN-paper-reading/visualization-3.png\">\n",
        "\n",
        "**Applying arithmetic in the input space**\n",
        "<img src=\"https://4.bp.blogspot.com/-0rilHKMWwTQ/WKFnwwv5QUI/AAAAAAAABRc/jDewod7JSikDgY5Xn957yPNzpCy4ZXmhwCK4B/w1200-h630-p-k-no-nu/dcgan-vector-arithmatic.PNG\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tp62jeLcvnL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42DK8IFGcvri",
        "colab_type": "text"
      },
      "source": [
        "## \n",
        "[참고자료]\n",
        "\n",
        "> 1시간만에 GAN(Generative Adversarial Network) 완전 정복하기\n",
        "https://www.youtube.com/watch?v=odpjk7_tGY0\n",
        "\n",
        "> Check out some other cool GAN projects\n",
        "https://github.com/nashory/gans-awesome-applications\n"
      ]
    }
  ]
}