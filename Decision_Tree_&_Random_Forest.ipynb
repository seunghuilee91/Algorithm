{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree & Random Forest.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjWRADvYASSa8LVC6PwxZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Deeplearning/blob/master/Decision_Tree_%26_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GUIdKhsWZgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0GPpjDhWeHJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Decision Tree (결정트리, 의사결정나무)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaZjGbd0WeTQ",
        "colab_type": "text"
      },
      "source": [
        "## 모델 소개\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "- 의사결정나무 학습법(Decision tree learning)은 어떤 항목에 대한 관측값과 목표값을 연결시켜주는 예측 모델로써 결정 트리를 사용한다.\n",
        "\n",
        "- 분류와 회귀 모두 가능한 모델이다. 즉 범주나 연속형 수치 모두 예측 가능하다.\n",
        "\n",
        "- 분류의 경우 최빈값, 회귀의 경우 종속변수(y)의 평균을 예측값으로 반환한다. 이 때 예측값의 종류는 terminal node개수와 일치한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYaOTGFWebf",
        "colab_type": "text"
      },
      "source": [
        "## 불순도 / 불확실성\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "- 분류나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가, 불순도(impurity) 혹은 불확실성(uncertainty)이 최대한 감소하도록 하는 방향으로 학습을 진행한다.\n",
        "\n",
        "- 순도가 증가/불확실성이 감소하는 걸 두고 정보이론에서는 **정보획득**(information gain)이라고 한다.\n",
        "\n",
        "#### 순도를 계산하는 3가지 방식\n",
        "> 1. 엔트로피(Entropy)\n",
        "\n",
        "> 2. 지니계수(Gini Index)\n",
        "\n",
        "> 2. 오분류오차(Misclassification Error)\n",
        "  '불순도를 측정할 수 있긴 하나 위 두 지표와 달리 미분이 불가능한 점 때문에 자주 쓰이지 않음 \n",
        "\n",
        "  \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "[참고] 엔트로피(entropy) <br>\n",
        "분포 p를 가진 H(X)로 표기되는 확률변수의 정보 엔트로피는 **불확실성의 측정**, = **놀람이 평균적인 정도** = **확률변수의 평균 정보량** 이다. 즉  확률 값임으로 0 ~ 1 사이의 실수를 가진며, 늘 양수이다. \n",
        "<br> 엔트로피가 '0'이라는 말은 현상이 발생할 확률이 0% 라는 것이다. 즉, 사건의 분포가 결정적(deterministic)이라면 해당 확률분포의 불확실성 정도를 나타내는 엔트로피는 낮아진다. 반대로 분포가 균등적(uniform)일 수록 엔트로피는 높아진다. (ex. 동전던지기, 엔트로피는 1이다. 결과값을 예상하기가 어렵기 때문이다.(불확실성 최대치)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ENjKb5Wei7",
        "colab_type": "text"
      },
      "source": [
        "## 모델 학습\n",
        "---\n",
        "<br>\n",
        "\n",
        "의사결정나무의 학습 과정은 입력 변수 영역을 두 개로 구분하는 **재귀적 분기(recursive partitioning)** 와 너무 자세하게 구분된 영역을 통합하는 가지치기(pruning) 두 가지로 과정으로 나뉜다.\n",
        "\n",
        "### 재귀적 분기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irGfDdYmdxex",
        "colab_type": "text"
      },
      "source": [
        "### 가지치기 (Pruning)\n",
        "- Terminal node의 순도가 100%인 상태를 Full tree라고 한다. 분기가 너무 많을 경우 학습데이터에 과적합(overfitting)할 우려가 있기 때문에 적절한 수준에서 **가지치기** 가 필요하다.\n",
        "\n",
        "- 결정나무의 분기 수가 일정한 수준 이상이 되면 오분류율이 오히려 증가하는 현상이 발생한다. 이에 검증데이터에 대한 오분류율이 증가하는 시점을 파악하여 적절히 가지치기를 수행해야 한다.\n",
        "\n",
        "- 나뭇가지를 잘라내는 것과 같다는 의미에서 용어가 붙었으나 실제 개념은 분기를 합치는 Merge이 개념으로 이해해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NidAQ7VwWel1",
        "colab_type": "text"
      },
      "source": [
        "## 장단점 및 활용\n",
        "#### 장점\n",
        "- 계산복잡성 대비 높은 예측 성능\n",
        "- 변수 단위 설명력\n",
        "#### 단점\n",
        "- 결정경계(decision boundary)가 데이터 축에 수직이어서 특정 데이터에만 잘 작동할 가능성 큼<br>\n",
        " ☞ *이를 극복하기 위해 **랜덤포레스트** 모델이 등장함*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmYtxzoJWepO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnV_MQiOWexO",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest(랜덤 포레스트)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_BOVDZGWeuo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK7l7mxVWesp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6blYilNgWeWT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}