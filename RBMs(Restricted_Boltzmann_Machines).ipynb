{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBMs(Restricted Boltzmann Machines).ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOnfvrUr4eY6pnkP2FmGZ/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghuilee91/Algorithm/blob/master/RBMs(Restricted_Boltzmann_Machines).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nASja5REYl9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW74Jw4WY28f",
        "colab_type": "text"
      },
      "source": [
        "# 제한 볼츠만 머신(Restricted Boltzmann Machine)\n",
        "---\n",
        "통계 물리(statistical physics)의 세부분야인 통계 역학(statistical mechanics)을 이용합니다. 따라서 통계 역학을 일군 볼츠만, 깁스 이름이 자주 등장합니다.\n",
        "\n",
        "<IMG SRC=\"https://i.ibb.co/K94zV1R/image.png\">\n",
        "\n",
        "> - BM은 학습이 매우어려워 거의 사용하지 않습니다.\n",
        "> - 대신 RBM(harmonium)이라는 **같은 종류의 노드 사이에는 에지를 허용하지 않는 구조**를 제안하게 됩니다(= Restricted 라는 이름이 붙게됨) .(Smolensky, 1986)\n",
        "> - 이후 대조발산(contrastive divergence) 학습 알고리즘이 제안되어 이 구조는 빛을 보게 됩니다.(Hinton, 2002)\n",
        "> - 그 후 RBM 층을 여러개 쌓아 만든 DBN(Deep belief network)가 제안되고, 빠르게 학습할 수 있는 층별 사전학습(layer-wise pretraining) 알고리즘이 제안되면서(Hinton, 2006) 딥러닝을 널리 확산하는 기폭제가 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy9prO6PY3DF",
        "colab_type": "text"
      },
      "source": [
        "## 1) RBM 구조와 원리\n",
        "---\n",
        "RBM은 노드값에 따라 에너지가 정해지며, 에너지가 낮을수록 발생 확률이 높습니다. RBM을 잘 학습하면, 원하는 특정 패턴을 높은 확률로 발생시킵니다. 즉, RBM은 원하는 샘플을 높은 확률로 생성하는 생성 모델(Generative model)이며, 역전파 알고리즘 등 분류 학습을 적용시키면 분별 모델(Discriminative model)로 사용할 수도 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_n-xKh6Y3GK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### RBM 구조\n",
        "RBM은 **무방향 바이파타이트 그래프(undirected bipartite graph)**입니다. 같은 종류 노드 사이에는 에지가 없고, 가시노드(visible node)와 은닉 노드(hidden node) 사이에만 노드가 있는 bipartite graph입니다.\n",
        "\n",
        "학습 시 알아내야 하는 매개변수는 가중치 W와 가시노드 바이어스 a, 은닉노드 바이어스 b 입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4JJv2XY3JJ",
        "colab_type": "text"
      },
      "source": [
        "### 에너지와 확률분포\n",
        "RBM 가시층과 은닉층에 x와 h값이 지정되면, 에너지 함수를 계산할 수 있습니다. 에너지를 통해 x, h 가 발생할 확률을 구할 수 있습니다. \n",
        "Z는 P(x, h)를 다 더하면 1이 되게 만들어줍니다. P(x, h)는 깁스 확률분포(Gibb's distribution)라고 합니다. 결합확률을 통해 확률 벡터 x가 발생할 확률을 구할 수 있습니다. x가 가질 수 있는 모든 경우에 대해 확률을 계산 할 수 있습니다.\n",
        "\n",
        "매개변수 값에 따라 에너지를 품고, 에너지는 샘플의 발생 확률을 규정합니다. 어떤 샘플은 자주발생하지만, 다른 샘플은 희소하게 발생하는 이유로 RBM을 스토캐스틱 생성 모델(Stochastic Generative Model)이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEZVATAxY3MH",
        "colab_type": "text"
      },
      "source": [
        "## 2) RBM 학습\n",
        "---\n",
        "3가지 단계를 반복함으로서 훈련\n",
        "\n",
        "1. forward : 입력 값을 내포하는 어떤 숫자 값으로 변역\n",
        "> <IMG SRC=\"https://steemitimages.com/1280x0/https://steemitimages.com/DQmY6tCGKVpkTEf3R3zjNHpVJd6JA1vNqUPjWGASpYBeNji/trainingrbm.PNG\">\n",
        "\n",
        "2. backward : 입력값에 대해 재구성(reconstruct)\n",
        "> <IMG SRC=\"https://steemitimages.com/DQmS15MDkL79sJDmtBKxtHsfXce9P1Xn4iZMiW3KL6gN4fZ/trainingrbm2.PNG\">\n",
        "\n",
        "3. 재구성된 값과 원래의 입력 값을 비교하여 평가 (비교시 KL Divergence, CD 알고리즘 등을 사용)\n",
        "\n",
        "\n",
        "\n",
        "### 이렇게 3단계를 입력값과 재구성된 값이 최대한 가까워 질 때까지 반복합니다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "> <IMG SRC=\"https://i.ibb.co/yfRdF1k/image.png\"> <BR>\n",
        "> - 은닉층 샘플링 → 가시층 샘플링 → 은닉층 샘플링 → 가중치 갱신 으로 작동합니다.<BR>\n",
        "> - 이 과정을 한 번만하면 CD1이라고 하며, 제대로 된 샘플을 얻기 위해서는 임의로 초기화된 가시 벡터로 시작해서 여러개의 샘플링 작업을 거친 CDn을 진행해야 합니다. (Hinton, 2002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX9q7pmyY3Oh",
        "colab_type": "text"
      },
      "source": [
        "## 3) RBM 응용\n",
        "\n",
        "- 차원축소에 쓰여 데이터를 비지도학습으로 분류하는데 쓰일 수 있습니다. MNIST에서 2차원 축소하였을 때 RBM은 PCA보다 좋은 성능을 거두었습니다.(Hinton, 2006)\n",
        "\n",
        "- 또한 정보검색, 협업 필터링 추천 시스템, 음성 인식 등에도 적용할 수 있습니다.\n",
        "\n",
        "- 지도학습으로 확장할 수도 있습니다.\n",
        "\n",
        " - RBM을 특징분류기로 사용하여 RBM 거친 노드들 뒷 단에 분류층을 두어 지도학습을 하거나,\n",
        "\n",
        " - 입력에서부터 레이블 정보 추가하여 높은 확률의 결과를 부류로 분류하는 것 등이 잇습니다.\n",
        "\n",
        "\n",
        " > ## [참고자료]\n",
        "> ### **Recognizing Latent Factors in The Data**\n",
        "> Lets consider the following example where a user likes Lord of the Rings and Harry Potter but does not like The Matrix, Fight Club and Titanic. The Hobbit has not been seen yet so it gets a -1 rating. Given these inputs the Boltzmann Machine may identify three hidden factors Drama, Fantasy and Science Fiction which correspond to the movie genres.\n",
        "> <IMG SRC=\"https://miro.medium.com/max/1050/1*ZY4c980_7MfEMYTIi6jvTw.png\">\n",
        "> Given the movies the RMB assigns a probability p(h|v) (Eq. 4) for each hidden neuron. The final binary values of the neurons are obtained by sampling from Bernoulli distribution using the probability p.\n",
        "> In this example only the hidden neuron that represents the genre Fantasy becomes activate. Given the movie ratings the Restricted Boltzmann Machine recognized correctly that the user likes Fantasy the most.\n",
        "> ### **Using Latent Factors for Prediction**\n",
        "> After the training phase the goal is to predict a binary rating for the movies that had not been seen yet. Given the training data of a specific user the network is able to identify the latent factors based on this users preference. Since the latent factors are represented by the hidden neurons we can use p(v|h) (Eq. 5) and sample from Bernoulli distribution to find out which of the visible neurons now become active.\n",
        "> It shows the new ratings after using the hidden neuron values for the inference. The network did identified Fantasy as the preferred movie genre and rated The Hobbit as a movie the user would like.\n",
        "> <IMG SRC=\"https://miro.medium.com/max/1050/1*De0RDPU_XRqT0BMAVE4vqA.png\">\n",
        "> - 1.Train the network on the data of all users\n",
        "> - 2.During inference time take the training data of a specific user\n",
        "> - 3.Use this data to obtain the activations of hidden neurons\n",
        "> - 4.Use the hidden neuron values to get the activations of input neurons\n",
        "> - 5.The new values of input neurons show the rating the user would give yet unseen movies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spiee1oqMRF0",
        "colab_type": "text"
      },
      "source": [
        "## 4) RBM 특징 \n",
        "\n",
        "- RBM은 Unsupervised Learning이기 때문에 우선 data가 labeled 되어 있을 필요가 없습니다. \n",
        "- 하지만 사실 RBM은 어떤 입력 feature가 중요하고, 어떻게 그들을 조합해서 패턴을 만들 것인지 결정하고 있습니다. \n",
        "- 그래서 RBM을 특성(feature)을 추출하는 신경망이라고도 부르며 이것은 Autoencoder라고도 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F97ALydlMRLN",
        "colab_type": "text"
      },
      "source": [
        "# 참고자료\n",
        "https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15\n",
        "\n",
        "https://ratsgo.github.io/statistics/2017/05/31/gibbs/ (깁스샘플링)\n",
        "\n",
        "https://m.blog.naver.com/PostView.nhn?blogId=hamjii&logNo=220128820369&proxyReferer=https:%2F%2Fwww.google.com%2F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MMGoozUMROt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}